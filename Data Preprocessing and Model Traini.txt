Data Preprocessing and Model Training for Diabetes:

def train_diabetes_model():
    # Load the dataset
    df = pd.read_csv('datasets/diabetes.csv')
    
    # Separate features (X) and target (y)
    X = df.drop('Outcome', axis=1)  # All columns except 'Outcome'
    y = df['Outcome']  # Target variable
    
    # Split data: 80% training, 20% testing
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Scale the features for better performance
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Train Random Forest model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)
    
    # Evaluate model
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)  # Achieved 72% accuracy

Heart Disease Model Training:

def train_heart_disease_model():
    # Load the dataset
    df = pd.read_csv('datasets/heart.csv')
    
    # Separate features and target
    X = df.drop('target', axis=1)
    y = df['target']
    
    # Similar process: split, scale, train
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)
    
    # Achieved 84% accuracy

Parkinson's Disease Model Training:

def train_parkinsons_model():
    # Load the dataset
    df = pd.read_csv('datasets/parkinsons.csv')
    
    # Remove 'name' column and separate features/target
    X = df.drop(['name', 'status'], axis=1)
    y = df['status']
    
    # Similar process: split, scale, train
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)
    
    # Achieved 95% accuracy



Data Preprocessing:

Load data from CSV files
Remove unnecessary columns
Split features (X) and target variable (y)


Feature Scaling:
Used StandardScaler to normalize features
Fit scaler on training data only
Transform both training and test data


Model Selection:

Used RandomForestClassifier because:
Handles both numerical and categorical data well
Less prone to overfitting
Provides feature importance
Good performance on medical datasets


Training Parameters:

n_estimators=100 (number of trees)
random_state=42 (for reproducibility)
80-20 train-test split
Model Evaluation:
Used accuracy_score and classification_report


Achieved accuracies:

Diabetes: 72%
Heart Disease: 84%
Parkinson's: 95%
Model and Scaler Saving:
Saved both model and scaler for each disease
Used joblib for saving (better for large NumPy arrays)

joblib.dump(model, 'model_name.sav')
joblib.dump(scaler, 'scaler_name.sav')


This approach ensures:

Consistent feature scaling between training and prediction
Good model performance
Reproducible results
Easy model deployment